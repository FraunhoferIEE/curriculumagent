[2023-06-28 15:10:22,526 I 117 117] (raylet) io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2023-06-28 15:10:22,529 I 117 117] (raylet) store_runner.cc:32: Allowing the Plasma store to use up to 6.08119GB of memory.
[2023-06-28 15:10:22,530 I 117 117] (raylet) store_runner.cc:48: Starting object store with directory /tmp, fallback /opt/project/jupyter_notebooks/data/tmp, and huge page support disabled
[2023-06-28 15:10:22,531 I 117 129] (raylet) dlmalloc.cc:154: create_and_mmap_buffer(6081216520, /tmp/plasmaXXXXXX)
[2023-06-28 15:10:22,538 I 117 129] (raylet) store.cc:554: ========== Plasma store: =================
Current usage: 0 / 6.08119 GB
- num bytes created total: 0
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2023-06-28 15:10:23,536 I 117 117] (raylet) grpc_server.cc:140: ObjectManager server started, listening on port 33113.
[2023-06-28 15:10:23,538 I 117 117] (raylet) worker_killing_policy.cc:101: Running GroupByOwner policy.
[2023-06-28 15:10:23,539 I 117 117] (raylet) memory_monitor.cc:47: MemoryMonitor initialized with usage threshold at 19803340800 bytes (0.95 system memory), total system memory bytes: 20845621248
[2023-06-28 15:10:23,540 I 117 117] (raylet) node_manager.cc:295: Initializing NodeManager with ID 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8
[2023-06-28 15:10:23,542 I 117 117] (raylet) grpc_server.cc:140: NodeManager server started, listening on port 41889.
[2023-06-28 15:10:23,549 I 117 160] (raylet) agent_manager.cc:109: Monitor agent process with id 424238335, register timeout 30000ms.
[2023-06-28 15:10:23,565 I 117 117] (raylet) event.cc:234: Set ray event level to warning
[2023-06-28 15:10:23,566 I 117 117] (raylet) event.cc:342: Ray Event initialized for RAYLET
[2023-06-28 15:10:23,570 I 117 117] (raylet) raylet.cc:117: Raylet of id, 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8 started. Raylet consists of node_manager and object_manager. node_manager address: 172.17.0.2:41889 object_manager address: 172.17.0.2:33113 hostname: ed91654137ea
[2023-06-28 15:10:23,578 I 117 117] (raylet) node_manager.cc:525: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 23 total (12 active)
[state-dump] Queueing time: mean = 5.664 ms, max = 27.099 ms, min = 20.774 us, total = 130.277 ms
[state-dump] Execution time:  mean = 45.602 ms, total = 1.049 s
[state-dump] Event stats:
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 10 total (2 active, 1 running), CPU time: mean = 687.721 us, total = 6.877 ms
[state-dump] 	UNKNOWN - 3 total (3 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1 total (0 active), CPU time: mean = 5.832 us, total = 5.832 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 931.588 us, total = 931.588 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 1.041 s, total = 1.041 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8
[state-dump] Node name: 172.17.0.2
[state-dump] InitialConfigResources: {node:172.17.0.2: 10000, memory: 121623822350000, object_store_memory: 60811911160000, CPU: 30000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: 479593857608511716 Local resources: {object_store_memory: [60811911160000]/[60811911160000], CPU: [30000]/[30000], memory: [121623822350000]/[121623822350000], node:172.17.0.2: [10000]/[10000]}node id: 479593857608511716{object_store_memory: 60811911160000/60811911160000, CPU: 30000/30000, node:172.17.0.2: 10000/10000, memory: 121623822350000/121623822350000}{ "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 6081191116
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 0
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 23 total (12 active)
[state-dump] Queueing time: mean = 5.664 ms, max = 27.099 ms, min = 20.774 us, total = 130.277 ms
[state-dump] Execution time:  mean = 45.602 ms, total = 1.049 s
[state-dump] Event stats:
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 10 total (2 active, 1 running), CPU time: mean = 687.721 us, total = 6.877 ms
[state-dump] 	UNKNOWN - 3 total (3 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1 total (0 active), CPU time: mean = 5.832 us, total = 5.832 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 931.588 us, total = 931.588 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 1.041 s, total = 1.041 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2023-06-28 15:10:23,581 I 117 117] (raylet) accessor.cc:611: Received notification for node id = 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8, IsAlive = 1
[2023-06-28 15:10:23,690 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 182, the token is 0
[2023-06-28 15:10:23,691 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 183, the token is 1
[2023-06-28 15:10:23,693 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 184, the token is 2
[2023-06-28 15:10:25,409 I 117 129] (raylet) object_store.cc:35: Object store current usage 8e-09 / 6.08119 GB.
[2023-06-28 15:10:25,422 I 117 117] (raylet) agent_manager.cc:40: HandleRegisterAgent, ip: 172.17.0.2, port: 57721, id: 424238335
[2023-06-28 15:10:25,523 I 117 117] (raylet) node_manager.cc:607: New job has started. Job id 01000000 Driver pid 1 is dead: 0 driver address: 172.17.0.2
[2023-06-28 15:10:25,524 I 117 117] (raylet) worker_pool.cc:672: Job 01000000 already started in worker pool.
[2023-06-28 15:10:32,543 W 117 122] (raylet) metric_exporter.cc:209: [1] Export metrics to agent failed: GrpcUnknown: RPC Error message: Method not found!; RPC Error details: . This won't affect Ray, but you can lose metrics from the cluster.
[2023-06-28 15:10:37,796 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 367, the token is 3
[2023-06-28 15:10:37,801 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 368, the token is 4
[2023-06-28 15:10:37,805 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 369, the token is 5
[2023-06-28 15:10:39,387 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = true
[2023-06-28 15:10:39,389 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = true
[2023-06-28 15:10:39,583 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = true
[2023-06-28 15:11:22,539 I 117 129] (raylet) store.cc:554: ========== Plasma store: =================
Current usage: 0 / 6.08119 GB
- num bytes created total: 56
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2023-06-28 15:11:23,582 I 117 117] (raylet) node_manager.cc:525: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 2987 total (17 active)
[state-dump] Queueing time: mean = 40.869 ms, max = 27.069 s, min = -0.000 s, total = 122.077 s
[state-dump] Execution time:  mean = 421.728 us, total = 1.260 s
[state-dump] Event stats:
[state-dump] 	UNKNOWN - 682 total (4 active), CPU time: mean = 13.778 us, total = 9.397 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 599 total (0 active), CPU time: mean = 5.786 us, total = 3.466 ms
[state-dump] 	NodeManager.CheckGC - 599 total (1 active), CPU time: mean = 2.161 us, total = 1.294 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 300 total (1 active), CPU time: mean = 22.266 us, total = 6.680 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 240 total (1 active), CPU time: mean = 329.354 us, total = 79.045 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 237 total (0 active), CPU time: mean = 64.741 us, total = 15.344 ms
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 76 total (4 active), CPU time: mean = 207.648 us, total = 15.781 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 60 total (0 active), CPU time: mean = 77.088 us, total = 4.625 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 60 total (1 active), CPU time: mean = 9.289 us, total = 557.318 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 20 total (0 active), CPU time: mean = 464.652 us, total = 9.293 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 12 total (0 active), CPU time: mean = 763.963 us, total = 9.168 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 12 total (1 active), CPU time: mean = 310.336 us, total = 3.724 ms
[state-dump] 	NodeInfoGcsService.grpc_client.CheckAlive - 12 total (0 active), CPU time: mean = 33.987 us, total = 407.842 us
[state-dump] 	NodeManager.GcsCheckAlive - 12 total (1 active), CPU time: mean = 188.314 us, total = 2.260 ms
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 20.813 us, total = 145.691 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 62.076 us, total = 434.534 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 905.429 ns, total = 6.338 us
[state-dump] 	ObjectManager.ObjectAdded - 7 total (0 active), CPU time: mean = 13.749 us, total = 96.242 us
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 6 total (1 active), CPU time: mean = 8.442 ms, total = 50.651 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 153.250 us, total = 766.249 us
[state-dump] 	CoreWorkerService.grpc_client.Exit - 3 total (0 active), CPU time: mean = 24.273 us, total = 72.819 us
[state-dump] 	RaySyncer.BroadcastMessage - 3 total (0 active), CPU time: mean = 169.250 us, total = 507.750 us
[state-dump] 	 - 3 total (0 active), CPU time: mean = 510.333 ns, total = 1.531 us
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 3 total (0 active), CPU time: mean = 17.179 us, total = 51.536 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 3 total (0 active), CPU time: mean = 6.977 us, total = 20.930 us
[state-dump] 	RaySyncerRegister - 2 total (0 active), CPU time: mean = 2.187 us, total = 4.374 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), CPU time: mean = 85.653 us, total = 171.305 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 17.789 us, total = 17.789 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 902.156 us, total = 902.156 us
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 1.139 ms, total = 1.139 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 931.588 us, total = 931.588 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 1.600 ms, total = 1.600 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 108.189 us, total = 108.189 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 1.041 s, total = 1.041 s
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 1 total (1 active, 1 running), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8
[state-dump] Node name: 172.17.0.2
[state-dump] InitialConfigResources: {node:172.17.0.2: 10000, memory: 121623822350000, object_store_memory: 60811911160000, CPU: 30000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 17
[state-dump] num_waiting_for_resource: 16
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 1
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: 479593857608511716 Local resources: {object_store_memory: [60811911160000]/[60811911160000], CPU: [0]/[30000], memory: [121623822350000]/[121623822350000], node:172.17.0.2: [10000]/[10000]}node id: 479593857608511716{object_store_memory: 60811911160000/60811911160000, CPU: 0/30000, memory: 121623822350000/121623822350000, node:172.17.0.2: 10000/10000}{ "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=368): {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=367): {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=369): {CPU: 1.000000}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 6081191116
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num PYTHON workers: 3
[state-dump] - num PYTHON drivers: 1
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 2987 total (17 active)
[state-dump] Queueing time: mean = 40.869 ms, max = 27.069 s, min = -0.000 s, total = 122.077 s
[state-dump] Execution time:  mean = 421.728 us, total = 1.260 s
[state-dump] Event stats:
[state-dump] 	UNKNOWN - 682 total (4 active), CPU time: mean = 13.778 us, total = 9.397 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 599 total (0 active), CPU time: mean = 5.786 us, total = 3.466 ms
[state-dump] 	NodeManager.CheckGC - 599 total (1 active), CPU time: mean = 2.161 us, total = 1.294 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 300 total (1 active), CPU time: mean = 22.266 us, total = 6.680 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 240 total (1 active), CPU time: mean = 329.354 us, total = 79.045 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 237 total (0 active), CPU time: mean = 64.741 us, total = 15.344 ms
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 76 total (4 active), CPU time: mean = 207.648 us, total = 15.781 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 60 total (0 active), CPU time: mean = 77.088 us, total = 4.625 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 60 total (1 active), CPU time: mean = 9.289 us, total = 557.318 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 20 total (0 active), CPU time: mean = 464.652 us, total = 9.293 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 12 total (0 active), CPU time: mean = 763.963 us, total = 9.168 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 12 total (1 active), CPU time: mean = 310.336 us, total = 3.724 ms
[state-dump] 	NodeInfoGcsService.grpc_client.CheckAlive - 12 total (0 active), CPU time: mean = 33.987 us, total = 407.842 us
[state-dump] 	NodeManager.GcsCheckAlive - 12 total (1 active), CPU time: mean = 188.314 us, total = 2.260 ms
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 20.813 us, total = 145.691 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 62.076 us, total = 434.534 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 905.429 ns, total = 6.338 us
[state-dump] 	ObjectManager.ObjectAdded - 7 total (0 active), CPU time: mean = 13.749 us, total = 96.242 us
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 6 total (1 active), CPU time: mean = 8.442 ms, total = 50.651 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 153.250 us, total = 766.249 us
[state-dump] 	CoreWorkerService.grpc_client.Exit - 3 total (0 active), CPU time: mean = 24.273 us, total = 72.819 us
[state-dump] 	RaySyncer.BroadcastMessage - 3 total (0 active), CPU time: mean = 169.250 us, total = 507.750 us
[state-dump] 	 - 3 total (0 active), CPU time: mean = 510.333 ns, total = 1.531 us
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 3 total (0 active), CPU time: mean = 17.179 us, total = 51.536 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 3 total (0 active), CPU time: mean = 6.977 us, total = 20.930 us
[state-dump] 	RaySyncerRegister - 2 total (0 active), CPU time: mean = 2.187 us, total = 4.374 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), CPU time: mean = 85.653 us, total = 171.305 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 17.789 us, total = 17.789 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 902.156 us, total = 902.156 us
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 1.139 ms, total = 1.139 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 931.588 us, total = 931.588 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 1.600 ms, total = 1.600 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 108.189 us, total = 108.189 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 1.041 s, total = 1.041 s
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 1 total (1 active, 1 running), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
[2023-06-28 15:11:23,640 W 117 117] (raylet) node_manager.cc:963: The actor or task with ID ffffffffffffffff9a474c9f995f12eb84f58c0b01000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.
Required resources for this actor or task: {CPU: 1.000000}
Available resources on this node: {object_store_memory: 60811911160000/60811911160000, CPU: 0/30000, memory: 121623822350000/121623822350000, node:172.17.0.2: 10000/10000} In total there are 0 pending tasks and 17 pending actors on this node.
[2023-06-28 15:11:23,642 W 117 117] (raylet) node_manager.cc:964: ========== Node: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8 =================
Infeasible queue length: 0
Schedule queue length: 0
Dispatch queue length: 17
num_waiting_for_resource: 16
num_waiting_for_plasma_memory: 0
num_waiting_for_remote_node_resources: 1
num_worker_not_started_by_job_config_not_exist: 0
num_worker_not_started_by_registration_timeout: 0
num_tasks_waiting_for_workers: 0
num_cancelled_tasks: 0
cluster_resource_scheduler state: 
Local id: 479593857608511716 Local resources: {object_store_memory: [60811911160000]/[60811911160000], CPU: [0]/[30000], memory: [121623822350000]/[121623822350000], node:172.17.0.2: [10000]/[10000]}node id: 479593857608511716{object_store_memory: 60811911160000/60811911160000, CPU: 0/30000, memory: 121623822350000/121623822350000, node:172.17.0.2: 10000/10000}{ "placment group locations": [], "node to bundles": []}
Waiting tasks size: 0
Number of executing tasks: 0
Number of pinned task arguments: 0
Number of total spilled tasks: 0
Number of spilled waiting tasks: 0
Number of spilled unschedulable tasks: 0
Resource usage {
    - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=368): {CPU: 1.000000}
    - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=367): {CPU: 1.000000}
    - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=369): {CPU: 1.000000}
}
Running tasks by scheduling class:
==================================================

[2023-06-28 15:11:23,690 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:11:33,718 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:11:43,750 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:11:53,783 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:12:03,813 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:12:13,838 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:12:22,540 I 117 129] (raylet) store.cc:554: ========== Plasma store: =================
Current usage: 0 / 6.08119 GB
- num bytes created total: 56
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2023-06-28 15:12:23,586 I 117 117] (raylet) node_manager.cc:525: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 5842 total (17 active)
[state-dump] Queueing time: mean = 21.029 ms, max = 27.069 s, min = -0.000 s, total = 122.849 s
[state-dump] Execution time:  mean = 257.370 us, total = 1.504 s
[state-dump] Event stats:
[state-dump] 	UNKNOWN - 1360 total (4 active), CPU time: mean = 14.495 us, total = 19.714 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1198 total (0 active), CPU time: mean = 6.617 us, total = 7.927 ms
[state-dump] 	NodeManager.CheckGC - 1198 total (1 active), CPU time: mean = 15.349 us, total = 18.388 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 600 total (1 active), CPU time: mean = 20.408 us, total = 12.245 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 480 total (1 active), CPU time: mean = 372.515 us, total = 178.807 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 477 total (0 active), CPU time: mean = 72.014 us, total = 34.350 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 120 total (0 active), CPU time: mean = 86.439 us, total = 10.373 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 120 total (1 active), CPU time: mean = 10.626 us, total = 1.275 ms
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 76 total (4 active), CPU time: mean = 207.648 us, total = 15.781 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 24 total (1 active), CPU time: mean = 352.171 us, total = 8.452 ms
[state-dump] 	NodeInfoGcsService.grpc_client.CheckAlive - 24 total (0 active), CPU time: mean = 34.428 us, total = 826.260 us
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 24 total (0 active), CPU time: mean = 21.256 us, total = 510.142 us
[state-dump] 	NodeManager.GcsCheckAlive - 24 total (1 active), CPU time: mean = 210.949 us, total = 5.063 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 20 total (0 active), CPU time: mean = 464.652 us, total = 9.293 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 12 total (0 active), CPU time: mean = 763.963 us, total = 9.168 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 12 total (1 active), CPU time: mean = 9.793 ms, total = 117.511 ms
[state-dump] 	RaySyncer.BroadcastMessage - 9 total (0 active), CPU time: mean = 147.417 us, total = 1.327 ms
[state-dump] 	 - 9 total (0 active), CPU time: mean = 573.556 ns, total = 5.162 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 62.076 us, total = 434.534 us
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 20.813 us, total = 145.691 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 905.429 ns, total = 6.338 us
[state-dump] 	ObjectManager.ObjectAdded - 7 total (0 active), CPU time: mean = 13.749 us, total = 96.242 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 153.250 us, total = 766.249 us
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 3 total (0 active), CPU time: mean = 17.179 us, total = 51.536 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 3 total (0 active), CPU time: mean = 6.977 us, total = 20.930 us
[state-dump] 	CoreWorkerService.grpc_client.Exit - 3 total (0 active), CPU time: mean = 24.273 us, total = 72.819 us
[state-dump] 	RaySyncerRegister - 2 total (0 active), CPU time: mean = 2.187 us, total = 4.374 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), CPU time: mean = 85.653 us, total = 171.305 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 2 total (1 active, 1 running), CPU time: mean = 2.521 ms, total = 5.043 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 1.139 ms, total = 1.139 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 902.156 us, total = 902.156 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 931.588 us, total = 931.588 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 1.600 ms, total = 1.600 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 108.189 us, total = 108.189 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 1.041 s, total = 1.041 s
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 17.789 us, total = 17.789 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8
[state-dump] Node name: 172.17.0.2
[state-dump] InitialConfigResources: {node:172.17.0.2: 10000, memory: 121623822350000, object_store_memory: 60811911160000, CPU: 30000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 17
[state-dump] num_waiting_for_resource: 16
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 1
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: 479593857608511716 Local resources: {object_store_memory: [60811911160000]/[60811911160000], CPU: [0]/[30000], memory: [121623822350000]/[121623822350000], node:172.17.0.2: [10000]/[10000]}node id: 479593857608511716{object_store_memory: 60811911160000/60811911160000, CPU: 0/30000, memory: 121623822350000/121623822350000, node:172.17.0.2: 10000/10000}{ "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=368): {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=367): {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=RolloutWorker.__init__ pid=369): {CPU: 1.000000}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 6081191116
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num PYTHON workers: 3
[state-dump] - num PYTHON drivers: 1
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 5842 total (17 active)
[state-dump] Queueing time: mean = 21.029 ms, max = 27.069 s, min = -0.000 s, total = 122.849 s
[state-dump] Execution time:  mean = 257.370 us, total = 1.504 s
[state-dump] Event stats:
[state-dump] 	UNKNOWN - 1360 total (4 active), CPU time: mean = 14.495 us, total = 19.714 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1198 total (0 active), CPU time: mean = 6.617 us, total = 7.927 ms
[state-dump] 	NodeManager.CheckGC - 1198 total (1 active), CPU time: mean = 15.349 us, total = 18.388 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 600 total (1 active), CPU time: mean = 20.408 us, total = 12.245 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 480 total (1 active), CPU time: mean = 372.515 us, total = 178.807 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 477 total (0 active), CPU time: mean = 72.014 us, total = 34.350 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 120 total (0 active), CPU time: mean = 86.439 us, total = 10.373 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 120 total (1 active), CPU time: mean = 10.626 us, total = 1.275 ms
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 76 total (4 active), CPU time: mean = 207.648 us, total = 15.781 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 24 total (1 active), CPU time: mean = 352.171 us, total = 8.452 ms
[state-dump] 	NodeInfoGcsService.grpc_client.CheckAlive - 24 total (0 active), CPU time: mean = 34.428 us, total = 826.260 us
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 24 total (0 active), CPU time: mean = 21.256 us, total = 510.142 us
[state-dump] 	NodeManager.GcsCheckAlive - 24 total (1 active), CPU time: mean = 210.949 us, total = 5.063 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 20 total (0 active), CPU time: mean = 464.652 us, total = 9.293 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 12 total (0 active), CPU time: mean = 763.963 us, total = 9.168 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 12 total (1 active), CPU time: mean = 9.793 ms, total = 117.511 ms
[state-dump] 	RaySyncer.BroadcastMessage - 9 total (0 active), CPU time: mean = 147.417 us, total = 1.327 ms
[state-dump] 	 - 9 total (0 active), CPU time: mean = 573.556 ns, total = 5.162 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 62.076 us, total = 434.534 us
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 20.813 us, total = 145.691 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 905.429 ns, total = 6.338 us
[state-dump] 	ObjectManager.ObjectAdded - 7 total (0 active), CPU time: mean = 13.749 us, total = 96.242 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 153.250 us, total = 766.249 us
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 3 total (0 active), CPU time: mean = 17.179 us, total = 51.536 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 3 total (0 active), CPU time: mean = 6.977 us, total = 20.930 us
[state-dump] 	CoreWorkerService.grpc_client.Exit - 3 total (0 active), CPU time: mean = 24.273 us, total = 72.819 us
[state-dump] 	RaySyncerRegister - 2 total (0 active), CPU time: mean = 2.187 us, total = 4.374 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), CPU time: mean = 85.653 us, total = 171.305 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 2 total (1 active, 1 running), CPU time: mean = 2.521 ms, total = 5.043 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 1.139 ms, total = 1.139 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 902.156 us, total = 902.156 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 931.588 us, total = 931.588 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 1.600 ms, total = 1.600 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 108.189 us, total = 108.189 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 1.041 s, total = 1.041 s
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 17.789 us, total = 17.789 us
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
[2023-06-28 15:12:23,863 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:12:33,879 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:12:43,892 I 117 117] (raylet) node_manager.cc:658: Sending Python GC request to 4 local workers to clean up Python cyclic references.
[2023-06-28 15:12:44,624 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=3, has creation task exception = true
[2023-06-28 15:12:44,625 I 117 117] (raylet) node_manager.cc:1552: Driver (pid=1) is disconnected. job_id: 01000000
[2023-06-28 15:12:44,636 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = true
[2023-06-28 15:12:44,639 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 632, the token is 6
[2023-06-28 15:12:44,644 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = true
[2023-06-28 15:12:44,648 I 117 117] (raylet) worker_pool.cc:489: Started worker process with pid 633, the token is 7
[2023-06-28 15:12:44,700 I 117 117] (raylet) node_manager.cc:1099: Owner process 01000000ffffffffffffffffffffffffffffffffffffffffffffffff died, killing leased worker 5fee930bd17e480377c3e24fe1d5689360dad1f34caf2f568722c3de
[2023-06-28 15:12:44,702 I 117 117] (raylet) node_manager.cc:607: New job has started. Job id 01000000 Driver pid 1 is dead: 1 driver address: 172.17.0.2
[2023-06-28 15:12:44,703 I 117 117] (raylet) worker_pool.cc:672: Job 01000000 already started in worker pool.
[2023-06-28 15:12:44,752 I 117 117] (raylet) node_manager.cc:1449: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = true
[2023-06-28 15:12:44,787 I 117 117] (raylet) main.cc:303: Raylet received SIGTERM, shutting down...
[2023-06-28 15:12:44,788 I 117 117] (raylet) accessor.cc:435: Unregistering node info, node id = 4b642b335b26d111b2c3aff1beca105c177e87edf8530cfecb7dbde8
[2023-06-28 15:12:44,789 I 117 117] (raylet) io_service_pool.cc:47: IOServicePool is stopped.
[0m