{
    "activation": "relu",
    "batchsize": 256,
    "dropout1": 0.19492379978847293,
    "dropout2": 0.1259373123876904,
    "initializer": "O",
    "layer1": 1414.960729971744,
    "layer2": 1251.8000886860257,
    "layer3": 1484.7748637079956,
    "layer4": 231.6874808929891,
    "learning_rate": 0.0003013467240068926,
    "TRIAL_BUDGET": 11
}