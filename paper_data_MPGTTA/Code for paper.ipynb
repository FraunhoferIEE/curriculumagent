{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5009f68-67ec-4db3-be15-dd0c0e6b4276",
   "metadata": {},
   "source": [
    "# Paper Ai2Go\n",
    "\n",
    "This is the jupter notebook for the planned paper. Here, we collect the results of the different SBATCH runs. This includes, the Teacher, Tutor but also Senior script. \n",
    "\n",
    "It is necessary to have the curriculum agent package installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3b06e1-c10b-40d7-a30e-0d1e86c2ba71",
   "metadata": {},
   "source": [
    "import os\n",
    "os.chdir('/home/mlehna/AI2Go/l2rpn_binbinchen_iee')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f4be54-ec47-42ea-9ab4-5975426d2a0e",
   "metadata": {},
   "source": [
    "import os\n",
    "import gym\n",
    "import grid2op\n",
    "from lightsim2grid import LightSimBackend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from lightsim2grid import LightSimBackend\n",
    "import grid2op\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "from curriculumagent.common.utilities import array2action, get_from_dict_set_bus, extract_action_set_from_actions,find_best_line_to_reconnect,is_legal,split_action_and_return\n",
    "from grid2op.Reward import RedispReward, L2RPNSandBoxScore\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import logging\n",
    "from l2rpn_baselines.ExpertAgent.expertAgent import ExpertAgent\n",
    "from typing import Dict, List, Optional, Tuple    \n",
    "import plotly.express as px\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "\n",
    "from grid2op.Agent import BaseAgent, DoNothingAgent\n",
    "from curriculumagent.common.score_agent import load_or_run,render_report\n",
    "from curriculumagent.submission.my_agent_advanced import MyAgent\n",
    "from curriculumagent.submission.my_agent import MyAgent as OldAgent\n",
    "from curriculumagent.tutor.tutors import original_tutor as original_tutor\n",
    "from curriculumagent.tutor.tutors.general_tutor import GeneralTutor\n",
    "\n",
    "from curriculumagent.tutor.tutors.n_minus_one_tutor import NminusOneTutor\n",
    "\n",
    "# Set Seed\n",
    "seed = 8888\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "date_strftime_format = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=date_strftime_format)\n",
    "\n",
    "tf.__version__"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e853342-c3c4-4ec9-8515-5f61ae56bfe0",
   "metadata": {},
   "source": [
    "#Collect test environment. If not available, use the track1_small environment\n",
    "if Path(\"/share/data1/GYM/data_grid2op/l2rpn_neurips_2020_test\").is_dir():\n",
    "    TEST_PATH = \"/share/data1/GYM/data_grid2op/l2rpn_neurips_2020_test\"\n",
    "else:\n",
    "    TEST_PATH = \"l2rpn_neurips_2020_track1_small\"\n",
    "    \n",
    "backend = LightSimBackend()\n",
    "env = grid2op.make(TEST_PATH, backend=backend)\n",
    "env.set_id(random.choice(range(24)))\n",
    "env.reset()\n",
    "env.chronics_handler.get_name()\n",
    "obs = env.get_obs()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3ae476-f292-4834-800a-825f3266d632",
   "metadata": {},
   "source": [
    "# Evaluation of Results \n",
    "\n",
    "Here we evaluate the results of the batch scrips. Below you can find the code for the Teacher-Tutor-Junior-Senior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b70d8-1cbd-4c76-8aba-662bf3ad72c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation of the Seed runs\n",
    "\n",
    "After realizing, that the seed is key for the performance of the different agents, we run a total of 30 random seeds to gather a unbiased result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9cdb54-deac-4d74-ba75-b9d715e34eca",
   "metadata": {},
   "source": [
    "from curriculumagent.tutor.tutor import general_tutor, n_minus_1_tutor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa75643a-c65c-470c-a1f8-73bd9e8234b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "with open('paper/seed_res.pkl', 'rb') as handle:\n",
    "    res_seed = pickle.load(handle)\n",
    "\n",
    "with open('paper/collect_survival_time.pkl', 'rb') as handle:\n",
    "    total_surv_time = pickle.load(handle)\n",
    "    \n",
    "\n",
    "names = ['Do Nothing Agent', 'Tutor Original', 'Tutor N-1','Tutor N-1 Topo', \"Expert Agent\",'Senior N-1 Topo checkpoint 1'] \n",
    "\n",
    "episode_names = ['apr19_1', 'apr19_2', 'aug02_1', 'aug02_2', 'dec16_1', 'dec16_2', 'feb20_1', 'feb20_2', 'jan32_1', 'jan32_2', 'jul28_1', 'jul28_2', 'jun14_1', 'jun14_2', 'mar39_1', 'mar39_2', 'may24_1', 'may24_2', 'nov46_1', 'nov46_2', 'oct05_1', 'oct05_2', 'sep21_1', 'sep21_2']\n",
    "\n",
    "episode_names_sorted = [ 'jan32_1', 'jan32_2','feb20_1', 'feb20_2','mar39_1', 'mar39_2', 'apr19_1', 'apr19_2',  'may24_1', 'may24_2','jun14_1', 'jun14_2', 'jul28_1', 'jul28_2', 'aug02_1', 'aug02_2','sep21_1', 'sep21_2','oct05_1', 'oct05_2','nov46_1', 'nov46_2',  'dec16_1', 'dec16_2']\n",
    "\n",
    "\n",
    "res_seed = pd.DataFrame(res_seed).transpose()\n",
    "print(res_seed.columns)\n",
    "res_seed.columns = names\n",
    "\n",
    "res_seed = res_seed[['Do Nothing Agent', \"Expert Agent\", 'Tutor Original', 'Tutor N-1',\n",
    "       'Tutor N-1 Topo', 'Senior N-1 Topo checkpoint 1']]\n",
    "\n",
    "comb_surv = {}\n",
    "for agent in total_surv_time[list(total_surv_time.keys())[0]].keys():\n",
    "    surv_accross_seeds = []\n",
    "    for s in list(total_surv_time.keys()):\n",
    "        surv_accross_seeds.append(total_surv_time[s][agent])\n",
    "    comb_surv[agent] = np.mean(np.array(surv_accross_seeds),axis=0)\n",
    "\n",
    "surv_df = pd.DataFrame(comb_surv,index = episode_names)\n",
    "surv_df = surv_df.loc[episode_names_sorted].reset_index()\n",
    "surv_df.columns = [\"episode_name\"]+names"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbd6e26-5d47-4763-bceb-49509dd36e9f",
   "metadata": {},
   "source": [
    "out = res_seed.describe().round(2)\n",
    "out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607dc77d-11cb-4cbe-8653-6c08426efd68",
   "metadata": {},
   "source": [
    "out['Tutor N-1 Topo'][\"mean\"]/out['Tutor Original'][\"mean\"] -1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0816bfae-6d97-4760-92ff-c03f3694684c",
   "metadata": {},
   "source": [
    "res_seed.boxplot(fontsize=\"xx-small\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "64f15b3b-5098-4ee8-9544-56b55749a411",
   "metadata": {},
   "source": [
    "#### Check for normal distribution of results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a15627-b798-4988-9afd-f86396029da9",
   "metadata": {},
   "source": [
    "# D’Agostino and Pearson’s Test for normality with H_0: X ~N(mu,sigma)\n",
    "from scipy import stats\n",
    "for k in res_seed.columns: \n",
    "    k2, p = stats.normaltest(res_seed[k])\n",
    "    print(f\"The results of {k} have a p-value of {p} to be normal distributed\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4a79a45c-2651-42ed-9c31-f95ee624777f",
   "metadata": {},
   "source": [
    "Due to the fact that we can not reject the null hypothesis it could be possible that the data is normally distributed \n",
    "\n",
    "\n",
    "Now we test for the difference in sample with the Welch test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef99d0d-48e5-4c90-9d3d-7dd2407d1cc3",
   "metadata": {},
   "source": [
    "test_c = [['Tutor Original',\"Tutor N-1\"],['Tutor Original',\"Tutor N-1 Topo\"] ,[\"Tutor N-1\",\"Tutor N-1 Topo\"] ,[\"Tutor N-1 Topo\",'Senior N-1 Topo checkpoint 1']]\n",
    "\n",
    "alpha = 0.05\n",
    "res_dict= {}\n",
    "\n",
    "for test_obj in test_c:\n",
    "    k2,p = stats.ttest_ind(res_seed[test_obj[0]], res_seed[test_obj[1]], equal_var=False)\n",
    "    if p < alpha: \n",
    "        out = f\"We reject the H_0 hypothesis with a p-value of {p} and an alpha of {alpha}\"\n",
    "    else:\n",
    "        out = f\"We can not reject the H_0 hypothesis with a p-value of {p} and an alpha of {alpha}\"\n",
    "    \n",
    "    print(f\"Testing, whether the {test_obj[0]} and the {test_obj[1]} agent are from the same distribution. \\n-> {out}\")\n",
    "    print()\n",
    "    res_dict[test_obj[0]+\" vs. \"+test_obj[1]] = p\n",
    "#pd.DataFrame(res_dict,index=[\"p-values\"]).to_latex()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e88f6f98-be48-402e-92d4-f4b82e75f8b4",
   "metadata": {},
   "source": [
    "## Plots and specific result of seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f72def91-2976-4397-b924-829333990213",
   "metadata": {},
   "source": [
    "seed_pick = random.choice(res_seed.index)\n",
    "print(seed_pick)\n",
    "res_seed.loc[seed_pick]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce365cb0-5e4e-4e6f-8dba-95e641f57a3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "backend = LightSimBackend()\n",
    "env = grid2op.make(TEST_PATH,backend=backend)\n",
    "test_flag=False\n",
    "\n",
    "reward = RedispReward\n",
    "other_rewards = {'grid_operation_cost': L2RPNSandBoxScore}\n",
    "if Path(\"/share/data1/GYM/single_seed/\"+str(seed_pick)).is_dir():\n",
    "    out_path =Path(\"/share/data1/GYM/single_seed/\"+str(seed_pick))\n",
    "else:\n",
    "    out_path = Path(\"single_seed/\"+str(seed_pick))\n",
    "    \n",
    "\n",
    "    \n",
    "# # Do nothing\n",
    "do_nothing_agent = DoNothingAgent(env.action_space)\n",
    "dn_report = load_or_run(agent = do_nothing_agent, env =env, output_path =out_path, name=\"DoNothing\",nb_processes=1, number_episodes=24,seed =seed_pick, reinit=True )\n",
    "\n",
    "#     # ------------------  Old Tutor  --------------------- #\n",
    "\n",
    "tutor_original = original_tutor.Tutor(env.action_space, old_actionspace_path=Path(\"paper/action_spaces_paper\"))\n",
    "tutor_original_report = load_or_run(tutor_original, env = env,output_path = out_path, name=\"Tutor Original\",nb_processes=1, number_episodes=24,seed =seed_pick )\n",
    "\n",
    "\n",
    "# # Expert Agent: \n",
    "expert_agent = ExpertAgent(action_space = env.action_space,\n",
    "                           observation_space = env.observation_space,\n",
    "                           name= \"Expert\",\n",
    "                           gridName=\"IEEE118_R2\")\n",
    "exp_report = load_or_run(agent = expert_agent, env =env, output_path =out_path, name=\"ExpertAgent\",nb_processes=1, number_episodes=24,seed =seed_pick )\n",
    "\n",
    "actions_n_minus_1 = [Path('paper/action_spaces_paper/n-1_actions_best_number.npy'),\n",
    "                     Path('paper/action_spaces_paper/actions62.npy'),\n",
    "                     Path('paper/action_spaces_paper/actions146.npy')]\n",
    "\n",
    "# N-1 Agent: \n",
    "tutor_n1 = NminusOneTutor(action_space=env.action_space,\n",
    "                       action_space_file = actions_n_minus_1,\n",
    "                       do_nothing_threshold=0.9,\n",
    "                       best_action_threshold=0.99,\n",
    "                       rho_greedy_threshold=0.99,\n",
    "                       lines_to_check=[45, 56, 0, 9, 13, 14, 18, 23, 27, 39],\n",
    "                       return_status=True)\n",
    "\n",
    "\n",
    "tutor_n1_repo = load_or_run(tutor_n1, env =env,output_path = out_path, name=\"Tutor N-1\",nb_processes=1, number_episodes=24,seed =seed_pick )\n",
    "\n",
    "# N-1 Agent: \n",
    "tutor_n1_topo = NminusOneTutor(action_space=env.action_space,\n",
    "                       action_space_file = actions_n_minus_1,\n",
    "                       do_nothing_threshold=0.9,\n",
    "                       best_action_threshold=0.99,\n",
    "                       rho_greedy_threshold=0.99,\n",
    "                       lines_to_check=[45, 56, 0, 9, 13, 14, 18, 23, 27, 39],\n",
    "                       return_status=True,\n",
    "                       revert_to_original_topo = True)\n",
    "\n",
    "\n",
    "tutor_n1_topo = load_or_run(tutor_n1_topo, env =env,output_path = out_path, name=\"Tutor N-1 Topo\",nb_processes=1, number_episodes=24,seed =seed_pick )\n",
    "\n",
    "with open('scaler_junior.pkl', \"rb\") as fp:   #Pickling\n",
    "    scaler = pickle.load(fp)\n",
    "\n",
    "my_agent_ckpt = MyAgent(\n",
    "            action_space = env.action_space,\n",
    "            model_path = Path(\"paper/checkpoint\"),\n",
    "            action_space_path = actions_n_minus_1,\n",
    "            scaler = scaler,\n",
    "            best_action_threshold = 0.95,\n",
    "            topo = True\n",
    "            )\n",
    "ckpt_repo = load_or_run(my_agent_ckpt, env =env,output_path = out_path, name=\"Senior N-1 Topo\",nb_processes=1, number_episodes=24,seed =seed_pick )\n",
    "\n",
    "# Overwrite names if necessary: \n",
    "ckpt_repo.agent_name = \"Senior N-1 Topo\"\n",
    "dn_report.agent_name = \"DoNothing Agent\"\n",
    "exp_report.agent_name = \"Expert Agent\"\n",
    "tutor_original_report.agent_name = \"Tutor Original\"\n",
    "tutor_n1_repo.agent_name = \"Tutor N-1\"\n",
    "tutor_n1_topo.agent_name = \"Tutor N-1 Topo\"\n",
    "\n",
    "reports = [exp_report,\n",
    "           tutor_original_report,\n",
    "           tutor_n1_repo,\n",
    "           tutor_n1_topo,\n",
    "           ckpt_repo\n",
    "           ] \n",
    "\n",
    "\n",
    "render_report(Path('report.md'),dn_report, reports)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c96f2d93-dad1-4cac-9685-4db712077f40",
   "metadata": {},
   "source": [
    "### Let's analyze the actions of the different agents: \n",
    "For this we run different plotting methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce192fdc-f183-4872-b0ec-e0cab9d45854",
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_actions_by_station_by_id(agents_results,agent_names, title, **fig_kwargs):\n",
    "       \n",
    "    comb_df = {}\n",
    "    substations,act_ids = [],[]\n",
    "    for name in agent_names:\n",
    "        # Note, we adjusted the agents_results in order to work. You most likely have to skipp some of this code\n",
    "        agent = agents_results.agents_data[agents_results.agents_names.index(name)]\n",
    "        df  = agent.get_actions_by_substation_by_id_adj()\n",
    "        comb_df[name] = df\n",
    "        substations += list(df['susbtation'].unique())\n",
    "        act_ids += list(df['action_id'].unique())\n",
    "        \n",
    "    substations = list(set(substations))\n",
    "    act_ids = list(set(act_ids))\n",
    "    \n",
    "    replacement = {act:f\"act_{i}\" for i,act in enumerate(act_ids)}\n",
    "    \n",
    "    # Shuffle the substations to get the better colormap\n",
    "    random.seed(1)\n",
    "    random.shuffle(substations)\n",
    "    \n",
    "    cmap = mpl.cm.turbo\n",
    "    cmap = mpl.cm.rainbow\n",
    "    norm = mpl.colors.Normalize(vmin=1, vmax= len(substations)+1)\n",
    "    cm = mpl.cm.ScalarMappable(cmap=cmap,norm=norm)\n",
    "    color_dict = {sb: colors.to_hex(cm.to_rgba(len(substations)+1-i)) for i,sb in enumerate(substations)}\n",
    "    color_dict\n",
    "    \n",
    "    all_figs = []\n",
    "    for name in agent_names:\n",
    "        df_n= comb_df[name].copy()\n",
    "        df.sort_values(\"susbtation\",ascending=False,inplace=True)\n",
    "        # Replace action values: \n",
    "        df_n.replace({\"action_id\":replacement},inplace=True)    \n",
    "        comb_df[name] = df_n.copy()\n",
    "        \n",
    "        df_n[\"color\"] = df_n[\"susbtation\"].map(color_dict)\n",
    "        fig = px.sunburst(df_n, path=['susbtation', 'action_id'], values='nb_action',\n",
    "                          # title=title + name,\n",
    "                          color = 'susbtation',color_discrete_map =color_dict,template=\"plotly_white\")\n",
    "        #fig.update_layout(**fig_kwargs)\n",
    "        fig.write_image(f\"actions_by_station_id{name}.pdf\")\n",
    "        all_figs.append(fig)\n",
    "    \n",
    "    return all_figs,comb_df\n",
    "\n",
    "def plot_bar_compa(score:pd.DataFrame, path:str) -> None:\n",
    "    \"\"\"\n",
    "    Create Bar Plot of the perfomance\n",
    "    Args:\n",
    "        reports: Reports of the agents\n",
    "        path: where to save the plot\n",
    "\n",
    "    Returns: None\n",
    "\n",
    "    \"\"\"\n",
    "    score_sub = score[[\"episode_name\",'Do Nothing Agent', \"Expert Agent\", 'Tutor Original', 'Tutor N-1','Tutor N-1 Topo', 'Senior N-1 Topo checkpoint 1']]\n",
    "    # Rename for plot: \n",
    "    score_sub.columns = [\"episode_name\",\n",
    "                         f\"DoNothing Agent: {score['Do Nothing Agent'].mean().round(1) }     \",\n",
    "                         f\"Expert Agent: {score['Expert Agent'].mean().round(1)}     \",\n",
    "                         f\"Tutor Original: {score['Tutor Original'].mean().round(1)}     \",\n",
    "                         f\"Tutor N-1: {score['Tutor N-1'].mean().round(1)}     \",\n",
    "                         f\"Tutor N-1 Topo: {score['Tutor N-1 Topo'].mean().round(1)}     \",\n",
    "                         f\"Senior N-1 Topo: {score['Senior N-1 Topo checkpoint 1'].mean().round(1)}     \"]\n",
    "    legends =list(score_sub.columns[1:])\n",
    "    legends.reverse()\n",
    "    \n",
    "    fig = px.bar(score_sub, x=\"episode_name\", y=legends, title=\"\",barmode='group',template=\"plotly_white\",width = 1000,height=500\n",
    "                )\n",
    "\n",
    "    fig.update_layout(xaxis={'rangeslider': {'visible': False}}, \n",
    "                      xaxis_title='Episode Name', yaxis_title='Average time steps survived')\n",
    "    fig.update_layout(legend=dict(\n",
    "        title=\"\",\n",
    "        orientation=\"h\",\n",
    "        entrywidth=140,\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"left\",\n",
    "        x=0.0\n",
    "    ))\n",
    "\n",
    "    fig.write_image(path)\n",
    "    \n",
    "def create_box(data):\n",
    "    \"\"\"\n",
    "    Creating the Boxplot of the agents\n",
    "    \"\"\"\n",
    "    res_seedc =data.copy()\n",
    "    res_seedc.columns = [f\"Do Nothing: {res_seedc['Do Nothing Agent'].median().round(2)}\",\n",
    "                         f\"Expert: {res_seedc['Expert Agent'].median().round(2)}\",\n",
    "                         f\"Original Tutor: {res_seedc['Tutor Original'].median().round(2)}\",\n",
    "                         f\"Tutor N-1: {res_seedc[ 'Tutor N-1'].median().round(2)}\",\n",
    "                         f\"Tutor N-1 Topo: {res_seedc['Tutor N-1 Topo'].median().round(2)}\",\n",
    "                         f\"Senior N-1 Topo: {res_seedc['Senior N-1 Topo checkpoint 1'].median().round(2)}\"]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    # Use x instead of y argument for horizontal plot\n",
    "    names =  list(res_seedc.columns).copy()\n",
    "    names.reverse()\n",
    "    for name in names:\n",
    "        fig.add_trace(go.Box(x=res_seedc[name],name=name,\n",
    "                            boxpoints='all', # can also be outliers, or suspectedoutliers, or False\n",
    "                            jitter=0.3, # add some jitter for a better separation between points\n",
    "                            pointpos=-1.8 # relative position of points wrt box\n",
    "                            ))\n",
    "\n",
    "    fig.update_layout(legend=dict(\n",
    "                                    title=\"\",\n",
    "                                    orientation=\"h\",\n",
    "                                    entrywidth=160,\n",
    "                                    yanchor=\"bottom\",\n",
    "                                    y=1.02,\n",
    "                                    xanchor=\"left\",\n",
    "                                    x=0.0\n",
    "                                ),\n",
    "                      yaxis =  {'showticklabels': False,\n",
    "                                'title': {'text': 'Agents'}},\n",
    "                      xaxis = {'title': {'text': 'Total scenario score of agent per seed'}},\n",
    "\n",
    "\n",
    "                     template=\"plotly_white\",width =1000,height=500)\n",
    "\n",
    "    fig.write_image(\"ResultsBox.pdf\")\n",
    "    \n",
    "    \n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d13166-e39f-453c-bd4d-9740b6a1d076",
   "metadata": {
    "tags": []
   },
   "source": [
    "plotting = True\n",
    "\n",
    "if plotting:     \n",
    "    ####################################   All Seeds   ###############################################\n",
    "    # All Seeds\n",
    "    plot_bar_compa(score = surv_df, path = \"Survival.pdf\")\n",
    "    create_box(res_seed)\n",
    "    ##################################################################################################\n",
    "    \n",
    "    \n",
    "    ####################################  Single Seed  ###############################################\n",
    "    # Single Seed \n",
    "    agents_names= [\"Tutor Original\",\"Tutor N-1 Topo\",\"Senior N-1 Topo\"]\n",
    "    ##################################################################################################\n",
    "    \n",
    "    # Plotting of substations: \n",
    "    # Actions by station Id\n",
    "    from grid2bench.AgentsAnalytics import AgentsAnalytics\n",
    "    import plotly.io as pio\n",
    "    pio.renderers.default = 'jupyterlab'\n",
    "    \n",
    "    # Only after agent run !\n",
    "    agents = AgentsAnalytics(data_path=out_path / \"agent_logs\",agents_names=agents_names)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig,comb_df = plot_actions_by_station_by_id(agents_results= agents,agent_names =agents_names,\n",
    "                                                title = \" \"#\"Action set by substation an action\"\n",
    "                                               )\n",
    "    \n",
    "    ##################################################################################################\n",
    "    # Plotting of computation times (long and short plot)\n",
    "     # TODO: Transfer to Episode data \n",
    "    comb_list = []\n",
    "    for agent in agents.agents_data:\n",
    "        df = agent.computation_times_several_episodes().copy()\n",
    "        df.set_index(\"Timestamp\",inplace=True)\n",
    "        df.columns = [agent.agent_name]\n",
    "        comb_list.append(df)\n",
    "\n",
    "\n",
    "    com_df = pd.concat(comb_list,axis=1).dropna()\n",
    "    com_df.reset_index(inplace=True)\n",
    "    import plotly.express as px\n",
    "\n",
    "    df = com_df.copy()\n",
    "\n",
    "\n",
    "    fig = px.scatter(df, x=\"Timestamp\", y=com_df.columns, marginal_y=\"rug\",template=\"plotly_white\",\n",
    "                    labels={\n",
    "                         \"value\": \"Execution Time (in s)\",\n",
    "                         \"Timestamp\": \"Grid2Op Scenarios\",\n",
    "                         \"variable\": \"\"\n",
    "                     },width = 4000,height=400)\n",
    "    fig.update_layout(legend=dict(\n",
    "        orientation=\"h\",\n",
    "        entrywidth=100,\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"left\",\n",
    "        x=0.0\n",
    "    ))\n",
    "    #fig.update_xaxes(tickangle=90)\n",
    "    \n",
    "    fig.update_layout(xaxis = {'anchor': 'y', 'domain': [0.0, 0.75], 'title': {'text': 'Grid2Op Scenarios'}},\n",
    "                      xaxis2 =  {'anchor': 'y2','domain': [0.8, 1.0],'matches': 'x2','showgrid': False,'showline': False,'showticklabels': True,\n",
    "                                 'tickmode' :  'array',\"tickvals\" : ['Tutor Original',\n",
    "                                                                     'Tutor N-1 Topo',\n",
    "                                                                     'Senior N-1 Topo'],\n",
    "                                 \"ticktext\" : ['T_O', 'T_N-1', 'Senior'], 'title': {'text': 'Frequency'},\n",
    "                                \"ticklabelposition\": \"outside left\"},     \n",
    "                      yaxis2 = {'anchor': 'x2', 'domain': [0.0, 1.0], 'matches': 'y','showgrid': False, 'showline': True, 'showticklabels': False})\n",
    "    fig.write_image(\"Computation_time1.pdf\")\n",
    "    \n",
    "    print([f'Tutor Original: {com_df[\"Tutor Original\"].mean().round(4)}s',\n",
    "           f'Tutor N-1 Topo: {com_df[\"Tutor N-1 Topo\"].mean().round(4)}s',\n",
    "           f'Senior N-1 Topo: {com_df[\"Senior N-1 Topo\"].mean().round(4)}s'])\n",
    "    \n",
    "    fig = px.histogram(df, x=\"Timestamp\",y=com_df.columns, marginal=\"rug\",\n",
    "                       )\n",
    "    fig.write_image(\"Computation_time_large.pdf\")\n",
    "    com_df_copy = com_df.copy()\n",
    "    com_df_copy.columns = ['Timestamp', \n",
    "                      f'Tutor Original with mean:    {com_df_copy[\"Tutor Original\"].mean().round(4)}s',\n",
    "                      f'Tutor N-1 Topo with mean:   {com_df_copy[\"Tutor N-1 Topo\"].mean().round(4)}s',\n",
    "                      f'Senior N-1 Topo with mean: {com_df_copy[\"Senior N-1 Topo\"].mean().round(4)}s']\n",
    "    fig = px.scatter(com_df_copy, x=\"Timestamp\", y=com_df_copy.columns[1:], marginal_y=\"rug\",template=\"plotly_white\",\n",
    "                labels={\n",
    "                     \"value\": \"Execution Time (in s)\",\n",
    "                     \"Timestamp\": \"Grid2Op Scenarios\",\n",
    "                     \"variable\": \"\"\n",
    "                 },width = 500,height=400)\n",
    "    fig.update_layout(legend=dict(\n",
    "        title=\"\",\n",
    "        orientation=\"h\",\n",
    "        entrywidth=240,\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"left\",\n",
    "        x=0.0\n",
    "    ))\n",
    "    #fig.update_xaxes(tickangle=90)\n",
    "\n",
    "    fig.update_layout(xaxis = {'anchor': 'y', 'domain': [0.0, 0.65], 'title': {'text': 'Grid2Op Scenarios'},\n",
    "                              \"dtick\":\"M4\",\"tickformat\":\"%b\\n%Y\"\n",
    "                              },\n",
    "                      xaxis2 =  {'anchor': 'y2','domain': [0.7, 1.0],'matches': 'x2','showgrid': False,'showline': False,'showticklabels': True,#\"tickangle\":90,\n",
    "                                 'tickmode' :  'array',\"tickvals\" : list(com_df_copy.columns[1:]),\n",
    "                                 # ['Tutor Original',\n",
    "                                 #                                     'Tutor N-1 Topo',\n",
    "                                 #                                     'Senior N-1 Topo'],\n",
    "                                 \"ticktext\" : ['T_O', 'T_N-1', 'Senior'], 'title': {'text': '\\n Frequency'}, \n",
    "                                \"ticklabelposition\": \"outside right\"},     \n",
    "                      yaxis2 = {'anchor': 'x2', 'domain': [0.0, 1.0], 'matches': 'y','showgrid': False, 'showline': True, 'showticklabels': False})\n",
    "    fig.write_image(\"Computation_time_short.pdf\")\n",
    "    \n",
    "    ##################################################################################################\n",
    "    # Plotting specific episode: \n",
    "    \n",
    "        \n",
    "    ep = \"jul28_1\"\n",
    "    dist_list = []\n",
    "    for agent in agents.agents_data:\n",
    "        df = agent.distance_from_initial_topology(ep)\n",
    "        df.set_index(\"Timestamp\",inplace=True)\n",
    "        df.columns = [agent.agent_name]\n",
    "        dist_list.append(df)\n",
    "\n",
    "\n",
    "    dist_df = pd.concat(dist_list,axis=1).dropna()\n",
    "    dist_df.reset_index(inplace=True)\n",
    "    \n",
    "    fig = make_subplots(rows=3, cols=1,vertical_spacing = 0.1)\n",
    "\n",
    "    for i,name in enumerate(dist_df.columns[1:]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=dist_df[\"Timestamp\"], y=dist_df[name],mode='lines',name=name),#+markers\n",
    "            row=i+1, col=1\n",
    "        )\n",
    "    fig.update_layout(yaxis = dict(tickmode = 'array',\n",
    "                                   tickvals = [0,1, 2,3],\n",
    "                                   ticktext = [\"Original\"+ \"<br>\"+\"Topology\",'1', '2', '3']),\n",
    "                      yaxis2 = dict(tickmode = 'array',\n",
    "                                   tickvals = [0,1, 2,3],\n",
    "                                   ticktext = [\"Original\"+ \"<br>\"+\"Topology\",'1', '2', '3']),\n",
    "                      yaxis3 = dict(tickmode = 'array',\n",
    "                                   tickvals = [0,1, 2,3],\n",
    "                                   ticktext = [\"Original\"+ \"<br>\"+\"Topology\",'1', '2', '3']),\n",
    "                      height=600, width=600,\n",
    "                      title_text=\"\",\n",
    "                      legend=dict(\n",
    "                        orientation=\"h\",\n",
    "                        entrywidth=100,\n",
    "                        yanchor=\"bottom\",\n",
    "                        y=1.02,\n",
    "                        xanchor=\"left\",\n",
    "                        x=0.0),\n",
    "                      template=\"plotly_white\"                  \n",
    "                     )\n",
    "    fig.write_image(f\"Distance in topology {ep}.pdf\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##################################################################################################\n",
    "    # Plot Environment:\n",
    "    backend = LightSimBackend()\n",
    "    env = grid2op.make(TEST_PATH, backend=backend)\n",
    "    env.set_id(1)\n",
    "    env.reset()\n",
    "    name = env.chronics_handler.get_name()\n",
    "    obs = env.get_obs()\n",
    "    #Plot Environment\n",
    "    from grid2op.PlotGrid import PlotMatplot\n",
    "    plot_helper = PlotMatplot(env.observation_space)\n",
    "    fig = plot_helper.plot_obs(obs,storage_info=None,gen_info=None,load_info=None)\n",
    "    #fig.show()\n",
    "    fig.savefig(f\"Grid {name}.pdf\")\n",
    "    \n",
    "    \n",
    "    ##################################################################################################\n",
    "    # Other plots not used for paper: \n",
    "    # Plots based on Grid2Bench\n",
    "    # Cumulative Reward\n",
    "    fig  = AgentsAnalytics.plot_cumulative_reward(agents.agents_data)\n",
    "    fig.write_image(\"cum_Rew.pdf\")\n",
    "    \n",
    "    # Freq by station\n",
    "    fig = AgentsAnalytics.plot_actions_freq_by_station_pie_chart(\n",
    "    agents.agents_data,\n",
    "    col=3,\n",
    "    #title = \"Frequency of actions by station\"\n",
    "    )\n",
    "    \n",
    "    fig.write_image(\"actions_freq.pdf\")\n",
    "    \n",
    "    \n",
    "    for name,resdf in comb_df.items():\n",
    "        df_time = resdf[[\"susbtation\",\"action_id\",\"t_step\"]].groupby([\"susbtation\",\"action_id\"]).mean().reset_index()\n",
    "        df_numb = resdf[[\"susbtation\",\"action_id\",\"nb_action\"]].groupby([\"susbtation\",\"action_id\"]).sum().reset_index()\n",
    "        ordered = df_time.groupby([\"susbtation\"]).mean().reset_index().sort_values(\"t_step\")[\"susbtation\"]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(df_time[\"t_step\"],df_time[\"susbtation\"],'o')\n",
    "        #plt.title(\"Plot of substation action over time by the \"+ name)\n",
    "        ax.set_yticks(ordered)\n",
    "        #plt.show()\n",
    "        plt.savefig(f\"sub_action_of_agent {name}.pdf\") \n",
    "\n",
    "    fig = AgentsAnalytics.plot_lines_impact(\n",
    "            agents.agents_data,\n",
    "            title = \" \",# \"Overloaded lines\",\n",
    "            yaxis_type = \"linear\"\n",
    "            )\n",
    "    fig.write_image(\"Lines Overload.pdf\")\n",
    "\n",
    "    fig = AgentsAnalytics.plot_actions_freq_by_station(\n",
    "            agents.agents_data,\n",
    "            #title = \"Frequency of actions by station\",\n",
    "            yaxis_type = \"log\"\n",
    "            )\n",
    "    fig.write_image(\"Frequency by station.pdf\")\n",
    "    \n",
    "    fig = px.scatter(com_df, x=\"Timestamp\", y=com_df.columns[1:], marginal_y=\"rug\",template=\"plotly_white\",\n",
    "                labels={\n",
    "                     \"value\": \"Execution Time (in s)\",\n",
    "                     \"Timestamp\": \"Grid2Op Scenarios\",\n",
    "                     \"variable\": \"\"\n",
    "                 },width = 400,height=400)\n",
    "    fig.update_layout(legend=dict(\n",
    "        title=\"\",\n",
    "        orientation=\"h\",\n",
    "        entrywidth=240,\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"left\",\n",
    "        x=0.0\n",
    "    ))\n",
    "    #fig.update_xaxes(tickangle=90)\n",
    "\n",
    "    fig.update_layout(xaxis = {'anchor': 'y', 'domain': [0.0, 0.65], 'title': {'text': 'Grid2Op Scenarios'},\n",
    "                              \"dtick\":\"M4\",\"tickformat\":\"%b\\n%Y\"\n",
    "                              },\n",
    "                      xaxis2 =  {'anchor': 'y2','domain': [0.7, 1.0],'matches': 'x2','showgrid': False,'showline': False,'showticklabels': True,#\"tickangle\":90,\n",
    "                                 'tickmode' :  'array',\"tickvals\" : list(com_df.columns[1:]),\n",
    "                                 # ['Tutor Original',\n",
    "                                 #                                     'Tutor N-1 Topo',\n",
    "                                 #                                     'Senior N-1 Topo'],\n",
    "                                 \"ticktext\" : ['T_O', 'T_N-1', 'Senior'], 'title': {'text': '\\n Frequency'}, \n",
    "                                \"ticklabelposition\": \"outside right\"},     \n",
    "                      yaxis2 = {'anchor': 'x2', 'domain': [0.0, 1.0], 'matches': 'y','showgrid': False, 'showline': True, 'showticklabels': False})\n",
    "    fig.write_image(\"Computation_time_short.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b136f270-ea2e-4fbe-ab35-bdc3d8713219",
   "metadata": {
    "tags": []
   },
   "source": [
    "do_you_have_a_lot_of_time = False\n",
    "\n",
    "if do_you_have_a_lot_of_time:\n",
    "    # Make GIF from one Episode of the Senior agent:\n",
    "    from grid2op.Episode import EpisodeReplay\n",
    "    from grid2op.Agent import GreedyAgent, RandomAgent\n",
    "    from grid2op.Runner import Runner\n",
    "    from tqdm import tqdm\n",
    "    if plotting: \n",
    "        path_agent= out_path / \"/agent_logs/Senior N-1 Topo\"\n",
    "        # and now reload it and display the \"movie\" of this scenario\n",
    "        # We take an \"hard\" scenario, because the generation takes a lot of time. \n",
    "        plot_epi = EpisodeReplay(path_agent)\n",
    "        plot_epi.replay_episode(\"jan32_1\", gif_name=\"jan32_1\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc0b160-726b-43c8-bf33-ff8d825b7920",
   "metadata": {},
   "source": [
    "# Experiment Workflow: \n",
    "<span style=\"color:blue\">\n",
    "The next section shows the Experiment workflow. This requires quite a lot of calculation. We provide all scripts for the curriculum agent, also for slurm clusters. \n",
    "Add the paths after running the code \n",
    "</span>\n",
    "\n",
    "\n",
    "\n",
    "#### Files: \n",
    "\n",
    "Teacher:<br />\n",
    "`run_teacher_n1.py` -> Run the N-1 Search of the Teacher to get the experience<br />\n",
    "\n",
    "Tutor:<br />\n",
    "`run_tutor_N-1_topo.py` -> Run the N-1 Tutor to get the observation and action sets\n",
    "\n",
    "Junior: <br />\n",
    "`scaler_junior.pkl` -> Sklearn Scaler of the Junior Model <br />\n",
    "`config.yml` -> config file for the NNI Hyperparameter optimisation<br />\n",
    "`hps_junior_nni.py` -> Hyperparameter script for the Junior<br />\n",
    "`search_space.json` -> Search space of the hyperparameter<br />\n",
    "`best_params.json` -> Best parameters of the NNI search<br />\n",
    "\n",
    "Senior: <br />\n",
    "The training of the Senior is done in this notebook\n",
    "\n",
    "Evaluation: <br />\n",
    "`get_seed.py` -> Evaluation script of the different model, to evaluate the agents. The results is the `seed_res.pkl`, which we import in this notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642894e9-8a93-4809-9f59-82bf74bdb21d",
   "metadata": {},
   "source": [
    "## Teacher \n",
    "\n",
    "This section shows the code, where we collected the Teacher experience of the N-1 Action space. The N-1 Teacher was run before this on our cluster (code included).\n",
    "\n",
    "Adjust the paths in the methods accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d318f9-ca74-4a5c-9eb9-bd7b17edf144",
   "metadata": {},
   "source": [
    "from curriculumagent.teacher.collect_teacher_experience import make_unitary_actionspace\n",
    "gather_actions = False\n",
    "if gather_actions: \n",
    "    make_unitary_actionspace(action_space_file_path =Path(\"n1_actions.npy\") ,\n",
    "                             experience_csv_files = ['teacher_experience.csv'],\n",
    "                             env_name_path = \"l2rpn_neurips_2020_track1_small\",\n",
    "                             best_n = 300)\n",
    "    plt.ylim((0,200))\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4822abed-9698-45c3-81b7-8d086c5f3662",
   "metadata": {},
   "source": [
    "## Tutor\n",
    "\n",
    "Here, we collect the tutor data from running the N-1 Tutor (again on the cluster). The output is then the Junior data.\n",
    "\n",
    "Adjust the paths to your liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e96948-368f-4785-bb6e-7496d7a7cba2",
   "metadata": {},
   "source": [
    "from curriculumagent.tutor.collect_tutor_experience import prepare_dataset, generate_tutor_experience\n",
    "\n",
    "generate_data = False\n",
    "if generate_data:\n",
    "    prepare_dataset(traindata_path=Path(\"junior_n1_topo\"),\n",
    "                    target_path=Path(\"n1_topo\"),\n",
    "                    filtered_obs=True,\n",
    "                    dataset_name=\"n1data_topo\",\n",
    "                    seed=8888)  \n",
    "        "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ff0cc60f-e508-42c2-a3b3-e0c0ff6fd696",
   "metadata": {},
   "source": [
    "## Junior\n",
    "\n",
    "Let's aggregate the result of the junior and train with it. Thus we load The Dataset of n1_data_topo and use it as our scaler.\n",
    "\n",
    "After the creation, we look at the histogram and the maximum value: One can see that the N-1 Actions are used with a high proportion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b9d12-3e06-4bf1-b26b-701a9bc782f3",
   "metadata": {},
   "source": [
    "# Load The Dataset of n1_data_topo and use it as our scaler: \n",
    "from curriculumagent.junior.junior_student import Junior,load_dataset,train \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle \n",
    "\n",
    "run_simple_junior = True\n",
    "if run_simple_junior:\n",
    "    target = Path(\"junior_n1_topo\")\n",
    "    s_train, a_train, s_validate, a_validate, s_test, a_test = load_dataset(target,dataset_name=\"n1data_topo\")\n",
    "\n",
    "\n",
    "    scaler =StandardScaler()\n",
    "    s_tr_t = scaler.fit_transform(s_train)\n",
    "    s_val_t = scaler.transform(s_validate)\n",
    "    s_test_t = scaler.transform(s_test)\n",
    "\n",
    "    \n",
    "    print(np.max(a_test))\n",
    "    plt.hist(a_train,bins=150)\n",
    "    \n",
    "    with open('scaler_junior.pkl', 'wb') as fp:   #Pickling\n",
    "        pickle.dump(scaler,fp)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d8bc41e7-5e0a-46bb-aec2-b29a69457991",
   "metadata": {},
   "source": [
    "Now, let's train the Junior (as a test) prior to the hyperparameter configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecf939-0b45-48ae-b8fa-521199287cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "if run_simple_junior:\n",
    "    junior = Junior(trainset_size = len(a_train), epochs  = 1000,num_actions =np.max(a_test)+1, learning_rate  = 5e-7,activation = \"relu\")\n",
    "\n",
    "    history = junior.train(log_dir =  Path(\"tfboard\"),\n",
    "                  ckpt_dir = Path(\"ckpt-junior-n1\") ,\n",
    "                  x_train =  s_tr_t, y_train= a_train,\n",
    "                  x_validate = s_val_t, y_validate = a_validate,\n",
    "                epochs  = 1000)\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    junior.test( s_test_t, a_test)\n",
    "    junior.model.save(\"ckpt-junior-n1\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "84e128b4-0567-4704-8b99-376bb07ed510",
   "metadata": {},
   "source": [
    "#### Advanced Junior Model \n",
    "\n",
    "After the hyper-parameteroptimization, we now train the Junior with best hyperparameters.\n",
    "\n",
    "For this we have to use the advanced model to initialize it with the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ecfca-825c-4a4f-9485-4cd6d42fcc8d",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "with open('best_params.json') as json_file:\n",
    "    best_params = json.load(json_file)\n",
    "\n",
    "best_params[\"epochs\"] = 1000\n",
    "best_params[\"initializer\"] = tf.keras.initializers.Orthogonal()\n",
    "for name in [\"layer1\",\"layer2\",\"layer3\",\"layer4\"]:\n",
    "        best_params[name] = np.round(best_params[name])\n",
    "    \n",
    "best_params"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c24fee-e7e4-482f-9216-e268a57c7f15",
   "metadata": {},
   "source": [
    "from curriculumagent.junior.hyper_parameter_search.advanced_junior_student import AdvancedJunior"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb75ad-1104-4ab6-b4f8-696790271857",
   "metadata": {
    "tags": []
   },
   "source": [
    "run_adv_junior = False\n",
    "\n",
    "if run_adv_junior:\n",
    "    junior = AdvancedJunior(config=best_params,\n",
    "                            trainset_size=len(a_train),\n",
    "                            num_actions= np.max(a_test)+1,\n",
    "                            seed = 15)\n",
    "\n",
    "    history = junior.train(log_dir=Path('n1/train'),\n",
    "                           ckpt_dir=Path('n1/train'),\n",
    "                           patience=50,\n",
    "                           x_train=s_tr_t, y_train=a_train,\n",
    "                           x_validate=s_val_t, y_validate=a_validate)\n",
    "    print(junior.model.summary())\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "    junior.model.save(Path('n1_topo'))\n",
    "    junior.test(s_test_t, a_test)\n",
    "    \n",
    "    model = tf.keras.models.load_model(Path('best-junior-n1'))\n",
    "    \n",
    "    model.predict(s_test_t)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2c708d67-568a-4177-8b1a-62fc92037347",
   "metadata": {},
   "source": [
    "# Senior\n",
    "Now we can run the senior model. Due to some specifications of RLlib, this is quite dependent on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df2b41-b9ff-47af-9907-aff1fc1ed5a2",
   "metadata": {},
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "import ray.rllib as rllib\n",
    "import tensorflow as tf\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from curriculumagent.senior.rllib_execution.senior_env_rllib import SeniorEnvRllib\n",
    "from curriculumagent.senior.rllib_execution.senior_model_rllib import Grid2OpCustomModelTF, AdvancedCustomModel\n",
    "from curriculumagent.scripts.run_rllib_with_advanced_model import train_senior,try_configs,get_n1_experiment_configs\n",
    "from  grid2op.Reward import FlatReward\n",
    "from curriculumagent.senior.rllib_execution.TopoRew import TopoRew"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416c774-0376-435b-b7ed-c4a9dac8761c",
   "metadata": {},
   "source": [
    "print(tf.__version__)\n",
    "os.cpu_count()\n",
    "ray.shutdown()\n",
    "\n",
    "ray_training = True # True, False, Extraction\n",
    "NUM_TRIALS = 4\n",
    "NUM_CPUS = 32\n",
    "NUM_GPUS = 0\n",
    "\n",
    "if ray ==\"Extraction\": \n",
    "    ray.init(num_cpus=os.cpu_count(), object_store_memory=32000000000, num_gpus=1,log_to_driver=False,dashboard_port =8042,ignore_reinit_error=True)\n",
    "elif ray_training:\n",
    "    ray.init(num_cpus=NUM_CPUS, object_store_memory=32000000000, num_gpus=NUM_GPUS,log_to_driver=False,dashboard_port =8042,ignore_reinit_error=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(\"Ray works: {ray.is_initialized()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5c5e06-10e9-43e8-942f-2a365ecaa078",
   "metadata": {},
   "source": [
    "Now lets Init the Environment and the scalers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9656f-6b82-4add-9202-22efb9803f2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "with open('/home/mlehna/AI2Go/l2rpn_binbinchen_iee/scaler_junior.pkl', \"rb\") as fp:   #Pickling\n",
    "    scaler = pickle.load(fp)\n",
    "if ray.is_initialized():\n",
    "    ray_scal = ray.put(scaler)\n",
    "else:\n",
    "    ray_scal = scaler\n",
    "\n",
    "from pathlib import Path\n",
    "actions_n_minus_1 = [Path('action_spaces_paper/n-1_actions_best_number.npy'),\n",
    "                     Path('action_spaces_paper/actions62.npy'),\n",
    "                     Path('action_spaces_paper/actions146.npy')]\n",
    "junior_model = Path('/share/data1/GYM/junior/paper/n1_topo/junior')\n",
    "env_config = {\"action_space_path\":actions_n_minus_1,\n",
    "              \"env_path\": \"l2rpn_neurips_2020_track1_small\",\n",
    "              \"action_threshold\":0.95,\n",
    "              'filtered_obs':True,\n",
    "              'scaler': ray_scal,\n",
    "              'topo':True,\n",
    "              'alternative_rew': TopoRew\n",
    "             } #\n",
    "target = Path('best-junior-n1')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "with open('best_params.json') as json_file:\n",
    "    best_params = json.load(json_file)\n",
    "    \n",
    "best_params[\"epochs\"] = 1000\n",
    "best_params[\"initializer\"] = tf.keras.initializers.Orthogonal()\n",
    "for name in [\"layer1\",\"layer2\",\"layer3\",\"layer4\"]:\n",
    "        best_params[name] = np.round(best_params[name])\n",
    "    \n",
    "print(best_params)\n",
    "\n",
    "\n",
    "rllib_env = SeniorEnvRllib(env_config)\n",
    "a = rllib_env.reset()\n",
    "if False:\n",
    "    model = AdvancedCustomModel(obs_space = rllib_env.observation_space,\n",
    "                                action_space = rllib_env.action_space,\n",
    "                               num_outputs = rllib_env.action_space.n,\n",
    "                               model_config={},\n",
    "                               path_to_junior = junior_model,\n",
    "                               custom_config = best_params,\n",
    "                               name=\"Junior\")\n",
    "    obs = {\"obs\":a.reshape(1,-1)}\n",
    "    b = model.forward(input_dict = obs, state=1, seq_lens=None)\n",
    "    print(\"Model seems to be working\")\n",
    "    \n",
    "model_config = {\"path_to_junior\":target,\n",
    "                \"custom_config\":best_params}\n",
    "\n",
    "ModelCatalog.register_custom_model('SeniorN1',  AdvancedCustomModel)\n",
    "\n",
    "if ray_training:\n",
    "    rllib_env.reset()\n",
    "    done = False\n",
    "    while done==False: \n",
    "        act = random.choice(np.arange(rllib_env.action_space.n))\n",
    "        a,b,done,d = rllib_env.step(act)\n",
    "        print(act,done,b,rllib_env.step_in_env,max(a),min(a),rllib_env.single_env.nb_time_step)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "683b049e-84e0-4017-adbe-118f4e5a2723",
   "metadata": {},
   "source": [
    "Run training. Note this can take a while, so be cautious!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73adc8c0-8824-4afa-ae71-bb60f52e1182",
   "metadata": {
    "tags": []
   },
   "source": [
    "if isinstance(ray_training,bool) and ray_training==True:\n",
    "    pbt = PopulationBasedTraining(\n",
    "            time_attr=\"training_iteration\",\n",
    "            metric=\"episode_reward_mean\",\n",
    "            mode=\"max\",\n",
    "            perturbation_interval=50,\n",
    "            resample_probability=0.5,\n",
    "            # Specifies the mutations of these hyperparams\n",
    "            hyperparam_mutations={\n",
    "                \"lr\": [1e-3, 5e-4, 1e-4, 5e-5, 1e-5],\n",
    "                #\"sample_batch_size\": lambda: random.randint(1, 128),\n",
    "                #\"train_batch_size\": lambda: random.randint(2048, 8096),\n",
    "                #\"sgd_minibatch_size\": lambda: random.randint(20, 128),\n",
    "                \"num_sgd_iter\": lambda: random.randint(3, 10),\n",
    "                \"vf_loss_coeff\": lambda: random.uniform(0.5,1),\n",
    "                \"clip_param\": lambda: random.uniform(0.01, 0.5),\n",
    "                \"gamma\": lambda: random.uniform(0.975, 1),\n",
    "                \"entropy_coeff\": lambda: 10**-random.uniform(2,5)\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "    tune.run(\n",
    "        \"PPO\",\n",
    "        name=\"Senior TopoRew\",\n",
    "        checkpoint_freq=10,\n",
    "        scheduler= pbt,\n",
    "        keep_checkpoints_num = 100, \n",
    "        verbose = 0,\n",
    "        reuse_actors = True,\n",
    "        max_failures=3, \n",
    "        num_samples=NUM_TRIALS,\n",
    "        stop={\"training_iteration\": 5000},\n",
    "        config={\n",
    "            \"env\":  SeniorEnvRllib,\n",
    "            \"env_config\":env_config,\n",
    "            \"num_workers\":int((NUM_CPUS - NUM_TRIALS-2) / NUM_TRIALS),\n",
    "            \"num_envs_per_worker\": 1,\n",
    "            \"lr\": 5e-5,\n",
    "            \"num_gpus\":int(NUM_GPUS / NUM_TRIALS),\n",
    "            \"num_cpus_per_worker\": 1,\n",
    "            \"remote_worker_envs\": False,\n",
    "            \"model\":{\"custom_model\":  \"SeniorN1\",\"custom_model_config\": model_config},\n",
    "            \"framework\": \"tf\"\n",
    "        },\n",
    "    )\n",
    "    ray.shutdown()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f2a87d1f-6fee-44fd-ac87-ddb6958b14fe",
   "metadata": {},
   "source": [
    "### Load Senior Model and Create Agent\n",
    "After training you should load and save the model as tf-model\n",
    "\n",
    "\n",
    "Note: You have to add the path of the RLlib experiment by yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58c47b-540b-480c-b571-82245d2094e1",
   "metadata": {},
   "source": [
    "from curriculumagent.senior.rllib_execution.convert_rllib_ckpt import load_config, load_and_save_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7351eb-b83c-433f-b469-5568b0aaed7b",
   "metadata": {},
   "source": [
    "path_of_experiments = [ ### Enter Path of RLlib here ###]\n",
    "\n",
    "list_of_ckpt = []\n",
    "\n",
    "load_dict = {}\n",
    "for pt in path_of_experiments:\n",
    "    ckpts = [os.path.join(path, n) for path, subdirs, files in os.walk(pt)\n",
    "                         for n in files  if \"checkpoint-\" in n and \"tune_metadata\" not in n]\n",
    "    list_of_ckpt += ckpts\n",
    "    for name in ckpts:\n",
    "        load_dict[name[65:70]+\"_\"+name[75]+\"_\"+name[-4:] ] = [Path(pt),Path(name)]\n",
    "\n",
    "        \n",
    "if ray_training==\"Extraction\":\n",
    "               \n",
    "    for k,v in load_dict.items():\n",
    "        agent_path = Path(\"senior\")/k[:-5]\n",
    "\n",
    "        config, ckpt_path = load_config(v[0], latest=False)\n",
    "        config[\"env_config\"] = env_config\n",
    "        config[\"model\"][\"custom_model_config\"][\"custom_config\"] = model_config['custom_config']\n",
    "\n",
    "        best_checkpoint =v[1]\n",
    "        \n",
    "        ckpt_nr = k[-4:] if \"-\" not in k[-4:] else k[-3:]\n",
    "        if agent_path.is_dir():\n",
    "            if \"ckpt_\"+ckpt_nr in os.listdir(agent_path):\n",
    "                print(\"ckpt_\"+ckpt_nr+ \" already exists\")\n",
    "                continue\n",
    "        load_and_save_model(ckpt_path=best_checkpoint, config=config, save_path=agent_path,ckpt_nr=int(ckpt_nr))\n",
    "        print(f\"Done with {k}\")\n",
    "        \n",
    "    \n",
    "ray.shutdown()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8655f04b-13e6-4477-8b6f-7eec61b68146",
   "metadata": {},
   "source": [
    "The Agent were then run in the \"get_seed.py\" file together with the Tutors to get the final evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expert",
   "language": "python",
   "name": "expert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
