{
    "activation": "relu",
    "batchsize": 768,
    "dropout1": 0.1574742627080689,
    "dropout2": 0.40892435817065576,
    "initializer": "O",
    "layer1": 400.4760096008514,
    "layer2": 773.3127175747637,
    "layer3": 1043.7250613290387,
    "layer4": 343.5998714852505,
    "learning_rate": 0.00012878737839029552,
    "TRIAL_BUDGET": 33
}